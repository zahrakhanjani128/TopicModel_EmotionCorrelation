# TopicModel_EmotionCorrelation
You can watch a short clip regarding the dataset and all of the steps of this project here: https://youtu.be/H7xcnrfm9oU

## A high-level description of the data source

For our project, we will be using the IEMOCAP database. The database was collected and being provided by SAIL lab at USC. It is an acted, multimodal and multispeaker database that contains approximately 12 hours of audiovisual data, including video, speech, motion capture of face, text transcriptions. Our main focus in the project is to use the text transcripts from the data source. 

IEMOCAP database has multiple annotators like:
categorical labels, such as anger, happiness, sadness, neutrality
dimensional labels such as valence, activation, dominance. 
        
The database was first published in the paper titled - IEMOCAP: interactive emotional dyadic motion capture database and has been very popular and has been cited at least 1500 times in several research papers. 

The data is available on request from the website - https://sail.usc.edu/iemocap/. A small request form needs to be filled out with the organizational information to get access to the data. The release form can be accessed here - https://sail.usc.edu/iemocap/release_form.php

Also you can take a look at the slides for the project presentation:
https://docs.google.com/presentation/d/15VKTLb-7owSiTilCZL2QLt5kI5mR-n6jJEUkix2EZvM/edit#slide=id.g10334c6542e_0_126
